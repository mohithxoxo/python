{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club Loan Analysis with Logistic Regression\n",
    "\n",
    "The [Lending Club](https://www.lendingclub.com/) is an online marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return. Each borrower fills out a comprehensive application, providing their past financial history, the reason for the loan, and more. Lending Club evaluates each borrower’s credit score using past historical data and assigns an interest rate to the borrower. \n",
    "\n",
    "Approved loans are listed on the Lending Club website, where qualified investors can browse recently approved loans, the borrower’s credit score, the purpose for the loan, and other information from the application.  Basically, the benefit of peer-to-peer lending is the democratization of data. You can see each and every rejected, completed, ongoing, and available loan. While loan data excludes personally identifiable information, it does include attributes like credit rating, location, college education level, lines of credit, and descriptions of why the applicant needs the loan.\n",
    "\n",
    "Once an investor decides to fund a loan, the borrower then makes monthly payments back to Lending Club. Lending Club redistributes these payments to investors. This means that investors don’t have to wait until the full amount is paid off to start to see returns. If a loan is fully paid off on time, the investors make a return which corresponds to the interest rate the borrower had to pay in addition to the requested amount.\n",
    "\n",
    "Many loans aren’t completely paid off on time, however, and some borrowers default on the loan. \n",
    "\n",
    "We'll be working with some data from Lending Club.  The basic problem to be solved here is one of predicting loan default rate. Solving the problem here uses a logistic regression model that optimizes over attributes such as loan size, interest rate, application date, debt to income ratio, home ownership status, and description length.\n",
    "\n",
    "For additional examples of predicting whether borrowers are likely to pay or default on their loans using Lending Club data and machine learning see [here](https://www.dataquest.io/blog/machine-learning-preparing-data/) or [here](http://rstudio-pubs-static.s3.amazonaws.com/290261_676d9bb194ae4c9882f599e7c0a808f2.html). \n",
    "\n",
    "For the code associated with this note book see [lendingclub.py](./lendingclub.py) (included in this repo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "There are several sources of Lending Club data that you might be able to use to test the code:\n",
    "- [Kaggle 1](https://www.kaggle.com/wendykan/lending-club-loan-data)\n",
    "- [Kaggle 2](https://www.kaggle.com/wordsforthewise/lending-club)\n",
    "- [Data World](https://data.world/jaypeedevlin/lending-club-loan-data-2007-11) (data from 2007)\n",
    "- [Lending Club](https://www.lendingclub.com/auth/login?login_url=%2Finfo%2Fdownload-data.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lendingclub.py\n",
    "import csv\n",
    "import random\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import fieldparsers\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "import sklearn.metrics\n",
    "import sklearn.svm.libsvm\n",
    "import sklearn.svm\n",
    "\n",
    "\n",
    "MAX_INTEREST_RATE_TO_INVEST = 1.00\n",
    "RANDOMIZATION_AMOUNT = 0.002\n",
    "\n",
    "# Table-based classifier that bins on a single discrete input value and\n",
    "# averages output values\n",
    "class BinnedClassifier:\n",
    "\n",
    "    def __init__(self, csv_col=None):\n",
    "        self.csv_col = csv_col\n",
    "\n",
    "    def get_bins(self, A_csv):\n",
    "        return A_csv[self.csv_col] if self.csv_col != None else numpy.ones(A_csv.shape[0])\n",
    "\n",
    "    def fit(self, A, A_csv, b):\n",
    "        bins = self.get_bins(A_csv)\n",
    "        counts = {}\n",
    "        sums = {}\n",
    "        for bin, value in zip(bins, b):\n",
    "            counts[bin] = counts.setdefault(bin, 0) + 1\n",
    "            sums[bin] = sums.setdefault(bin, 0) + value\n",
    "\n",
    "        self.averages = {}\n",
    "        for k, count in counts.iteritems():\n",
    "            self.averages[k] = sums[k] / count\n",
    "        return self\n",
    "\n",
    "    def predict(self, A, A_csv):\n",
    "        bins = self.get_bins(A_csv)\n",
    "        return map(lambda x: self.averages.setdefault(x, 0), A_csv[self.csv_col])\n",
    "\n",
    "# Classifier that always predicts 1\n",
    "class TrueValuedClassifier:\n",
    "\n",
    "    def fit(self, A, A_csv, b):\n",
    "        return self\n",
    "\n",
    "    def predict(self, A, A_csv):\n",
    "        return numpy.ones(A.shape[0])\n",
    "\n",
    "class SkLearnClassifier:\n",
    "\n",
    "    def __init__(self, base_classifier):\n",
    "        self.base_classifier = base_classifier\n",
    "\n",
    "    def get_classifier_probabilities(self, A):\n",
    "        probabilities = self.base_classifier.predict_proba(A)\n",
    "        return probabilities[:,0]\n",
    "\n",
    "    def predict(self, A, A_csv):\n",
    "        preds = self.get_classifier_probabilities(A)        \n",
    "        return preds.T\n",
    "\n",
    "    def fit(self, A, A_csv, b):\n",
    "        self.base_classifier.fit(A, b)\n",
    "        return self\n",
    "\n",
    "# Normalization / validation / evaluation\n",
    "class LcLearner:\n",
    "\n",
    "    def __init__(self, data, csv_data):\n",
    "        self.data = data.copy()\n",
    "        self.normalize()\n",
    "        self.csv_data = csv_data\n",
    "        self.unnormalized_data = data.copy()\n",
    "\n",
    "    def normalize(self):\n",
    "        for c in self.data.dtype.names:\n",
    "            dc = self.data[c]\n",
    "            denom = max(dc) - min(dc)\n",
    "            if denom == 0: denom = 1\n",
    "            self.data[c] = (dc - min(dc)) / denom\n",
    "\n",
    "    def construct_matrix(self, cols):\n",
    "        A = numpy.zeros((len(self.data), len(cols)))\n",
    "        for i, c in enumerate(cols): A[:,i] = self.data[c]\n",
    "        return numpy.matrix(A)\n",
    "\n",
    "    class EvalResults:\n",
    "        def __init__(self, avg_prediction_error, actual_irates):\n",
    "            self.avg_prediction_error = avg_prediction_error\n",
    "            self.actual_irates = numpy.array(actual_irates)\n",
    "            self.loan_quantities = numpy.array([40, 80, 200, 300, 400, 500, 750, 1000])\n",
    "\n",
    "        def get_loan_quantities(self):\n",
    "            return self.loan_quantities\n",
    "\n",
    "        def return_for_loan_quantities(self):\n",
    "            return self.actual_irates[self.loan_quantities]\n",
    "\n",
    "        def __str__(self):\n",
    "            results = [\"Avg pred error: %f\" % (self.avg_prediction_error)]\n",
    "            for x in self.loan_quantities:\n",
    "                if len(self.actual_irates) >= x:\n",
    "                    results.append(\"Return rate top %d investments: %f\" % (x, self.actual_irates[x-1]))\n",
    "            return \"\\n\".join(results)\n",
    "\n",
    "    # Train model with specified cols and inputs and target_col as output\n",
    "    def evaluate(self, cols, target_col, classifier):\n",
    "        split_percent = 0.5\n",
    "        A = self.construct_matrix(cols)\n",
    "        b = self.unnormalized_data[target_col]\n",
    "        split = int(split_percent * len(b))\n",
    "        A_train = A[1:split,:]\n",
    "        A_train_csv = self.csv_data[1:split]\n",
    "        b_train = b[1:split]\n",
    "        A_test = A[split+1:len(b),:]\n",
    "        A_test_csv = self.csv_data[split+1:len(b)]\n",
    "        b_test = b[split+1:len(b)]\n",
    "        model = classifier.fit(A_train, A_train_csv, b_train)\n",
    "        preds = model.predict(A_test, A_test_csv)\n",
    "        errors = preds - b_test\n",
    "        avg_error = numpy.sum(abs(errors)) / errors.shape[0]\n",
    "\n",
    "        loan_values = numpy.zeros((len(b_test), ), dtype=[('pred_irate', '>f4'), ('rand', '>f4'), ('actual_irate', '>f4'), ('irate', '>f4')])\n",
    "\n",
    "        rand_vec = numpy.random.rand(len(b_test))\n",
    "        loan_values['pred_irate'] = (-1 * A_test_csv['interest_rate'] * preds * 0.01) + (rand_vec * RANDOMIZATION_AMOUNT)\n",
    "        loan_values['rand'] = rand_vec\n",
    "        loan_values['actual_irate'] = A_test_csv['interest_rate'] * b_test * 0.01\n",
    "        loan_values['irate'] = A_test_csv['interest_rate'] * 0.01\n",
    "        loan_values.sort(order='pred_irate')\n",
    "        loan_values['pred_irate'] *= -1\n",
    "\n",
    "        returns = []\n",
    "\n",
    "        for i, actual_return in enumerate(loan_values['actual_irate']):\n",
    "            if loan_values['irate'][i] > MAX_INTEREST_RATE_TO_INVEST: continue\n",
    "            # if i < 100: print \"%d: %.4f %.4f %.4f\" % (i, actual_return, loan_values['pred_irate'][i], loan_values['irate'][i])\n",
    "            returns.append(actual_return if len(returns) == 0 else actual_return + returns[-1])\n",
    "\n",
    "        counts = (1 + numpy.array(range(len(returns))))\n",
    "        returns = returns / counts\n",
    "\n",
    "        return self.EvalResults(avg_error, returns)\n",
    "\n",
    "\n",
    "    def evaluate_all(self, cols, target_col):        \n",
    "        num_investments = 80\n",
    "        def create_probabilistic_logistic_classifier():\n",
    "            clf = sklearn.linear_model.LogisticRegression(C=10000, penalty='l1', scale_C=True)\n",
    "            return SkLearnClassifier(clf)\n",
    "        eval_plc = lambda x: self.evaluate(x, target_col, create_probabilistic_logistic_classifier())\n",
    "        eval_true = lambda: self.evaluate(cols, target_col, TrueValuedClassifier())\n",
    "        eval_bin = lambda: self.evaluate(cols, target_col, BinnedClassifier(csv_col='credit_grade'))\n",
    "\n",
    "        num_trials = 20\n",
    "        return_sums = {'true': 0, 'binned': 0, 'logistic': 0}\n",
    "        funcs = {'true': eval_true, 'binned': eval_bin, 'logistic': lambda: eval_plc(cols)}\n",
    "        for i in range(num_trials):\n",
    "            for k, v in funcs.iteritems():\n",
    "                return_sums[k] += v().actual_irates[num_investments]\n",
    "        \n",
    "        print \"Average return rate for %d loans\" % (num_investments)\n",
    "        for k, v in return_sums.iteritems():\n",
    "            avg = v / num_trials\n",
    "            print \"%20s: %.4f\" % (k, avg)\n",
    "        \n",
    "        et = eval_true()\n",
    "        eb = eval_bin()\n",
    "        ep = eval_plc(cols)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(ep.get_loan_quantities(), ep.return_for_loan_quantities(),\n",
    "                 et.get_loan_quantities(), et.return_for_loan_quantities(),\n",
    "                 eb.get_loan_quantities(), eb.return_for_loan_quantities())\n",
    "        plt.ylabel('avg return')\n",
    "        plt.xlabel('loans invested')\n",
    "        plt.legend(('logistic regression', 'credit grade binning', 'default rate of 0'))\n",
    "        plt.savefig(\"plots/loans_invested.png\")\n",
    "\n",
    "        print \"\\n\\nAssuming no loan defaults:\\n%s\\n\\n\" % (et)\n",
    "        print \"Credit grade binning:\\n%s\\n\\n\" % (eb)\n",
    "        print \"With all cols:\\n%s\\n\\n\" % (ep)\n",
    "\n",
    "        print \"\\nReturns for %d investments:\" % (num_investments)\n",
    "        print \"%40s %5s %5s\" % (\"column\", \"only\", \"w/o\")\n",
    "        \n",
    "        print \"%40s %.4f %.4f\" % (\"all\", 0.0, eval_plc(cols).actual_irates[num_investments])\n",
    "        for c in cols:\n",
    "            cols_copy = copy.copy(cols)\n",
    "            cols_copy.remove(c)\n",
    "            print \"%40s %.4f %.4f\" % (c, eval_plc([c]).actual_irates[num_investments], eval_plc(cols_copy).actual_irates[num_investments])\n",
    "            #print \"%40s %.4f %.4f\" % (c, eval_plc([c]).avg_prediction_error, eval_plc(cols_copy).avg_prediction_error)\n",
    "\n",
    "\n",
    "class LcDataExtractedFeatures:\n",
    "\n",
    "    def create(self, raw_data):\n",
    "        self.columns = ['amount_requested', 'interest_rate', 'loan_length', 'application_date', 'credit_grade', 'status', 'one', 'actual_interest_rate', 'debt_to_income_ratio','monthly_income', 'fico_range', 'open_credit_lines', 'total_credit_lines', 'earliest_credit_line_date', 'home_ownership', 'expected_interest_rate', 'loan_id', 'description_length']\n",
    "\n",
    "        normalizers = {'application_date': self.parse_date,\n",
    "                       'earliest_credit_line_date': self.parse_date,\n",
    "                       'credit_grade': self.parse_credit_rating,\n",
    "                       'status': self.parse_status,\n",
    "                       'one': self.ones,\n",
    "                       'actual_interest_rate': self.actual_interest_rate,\n",
    "                       'expected_interest_rate': self.expected_interest_rate,\n",
    "                       'fico_range': self.parse_fico_range,\n",
    "                       'monthly_income': self.parse_monthly_income,\n",
    "                       'home_ownership': self.parse_home_ownership,\n",
    "                       'description_length': self.description_length}\n",
    "        dtypes = []\n",
    "        for c in self.columns: dtypes.append((c, '>f4'))\n",
    "        self.raw_data = raw_data\n",
    "        self.data = numpy.zeros((len(raw_data),), dtype=dtypes)\n",
    "        for c in self.columns:\n",
    "            f = lambda: self.identity(raw_data, c)\n",
    "            if c in normalizers:\n",
    "                f = lambda: normalizers[c](raw_data, c)\n",
    "            self.data[c] = f()\n",
    "\n",
    "    def description_length(self, d, col):\n",
    "        return map(lambda x: len(x), d['loan_description'])\n",
    "\n",
    "    def parse_home_ownership(self, d, col):\n",
    "        return map(lambda x: 0 if x == 'RENT' else 1, d[col])\n",
    "\n",
    "    def parse_monthly_income(self, d, col):\n",
    "        return map(lambda x: min(x, 100000), d[col])\n",
    "\n",
    "    def parse_fico_range(self, d, col):\n",
    "        x = numpy.zeros(len(d[col]))\n",
    "        for i, s in enumerate(d[col]):\n",
    "            try:\n",
    "                x[i] = int(s[0:3])\n",
    "            except ValueError:\n",
    "                x[i] = 660 # assume missing value / bad data is lowest possible credit score\n",
    "        return x\n",
    "\n",
    "    def actual_interest_rate(self, d, col):\n",
    "        is_default = self.parse_status(d, 'status')\n",
    "        return is_default * d['interest_rate']\n",
    "\n",
    "    def expected_interest_rate(self, d, col):\n",
    "        p_success = self.parse_status(d, 'status')\n",
    "        return p_success * d['interest_rate']\n",
    "\n",
    "    def ones(self, d, col):\n",
    "        return map(lambda x: 1, d['interest_rate'])\n",
    "\n",
    "    def parse_date(self, d, col):\n",
    "        return map(lambda x: time.mktime(x.timetuple()), d[col])\n",
    "\n",
    "    def parse_credit_rating(self, d, col):\n",
    "        return map(lambda x: ((ord(x[0]) - ord('A')) * 5) + int(x[1]), d[col])\n",
    "\n",
    "    def parse_status(self, d, col):\n",
    "        def loan_status_collection_probability(status):\n",
    "            # see https://www.lendingclub.com/info/statistics-performance.action for numbers\n",
    "            if status == 'Fully Paid':\n",
    "                return 1\n",
    "            elif status == 'Charged Off':\n",
    "                return 0\n",
    "            elif status == 'In Grace Period':\n",
    "                return 0.84\n",
    "            elif status == 'Late (16-30 days)':\n",
    "                return 0.77\n",
    "            elif status == 'Late (31-120 days)':\n",
    "                return 0.53\n",
    "            elif status == 'Default':\n",
    "                return 0.04\n",
    "            elif status == 'Performing Payment Plan':\n",
    "                return 0.5 # this status not listed, 50% is a guess\n",
    "            raise Exception(\"Unknown status %s\" % (status))\n",
    "\n",
    "        p_return = []\n",
    "        for i, status in enumerate(d[col]):\n",
    "            p_r = None\n",
    "            if status == 'Current':\n",
    "                T = d['amount_funded_by_investors'][i]\n",
    "                t = d['payments_to_date'][i]\n",
    "                percent_remaining = 1 if T == 0 else (T-t)/T # TODO: how can T be zero?\n",
    "                avg_default_rate = 0.07\n",
    "                expected_default_rate = avg_default_rate * percent_remaining\n",
    "                expected_default_rate = max(0, expected_default_rate)\n",
    "                p_r = 1 - expected_default_rate\n",
    "            else:\n",
    "                p_r = loan_status_collection_probability(status)\n",
    "            p_return.append(p_r)\n",
    "        return p_return\n",
    "\n",
    "    def identity(self, d, col):\n",
    "        return d[col]\n",
    "\n",
    "\n",
    "class LcPlotter:\n",
    "\n",
    "    def __init__(self, raw_data, normalized_data, features, targets):\n",
    "        self.features = features\n",
    "        self.raw_data = raw_data.copy()\n",
    "        self.normalized_data = normalized_data.copy()\n",
    "        self.targets = targets\n",
    "        subprocess.call([\"mkdir\", \"plots\"])\n",
    "\n",
    "    def plot_correlations(self):\n",
    "        smoothing_window = max(1, int(len(self.raw_data[self.targets[0]]) / 10))\n",
    "        for c_f in self.features:            \n",
    "            grouped_features = mlab.rec_groupby(self.normalized_data, [c_f], [(c_f, len, 'count')])\n",
    "            is_discrete = len(grouped_features) < 100\n",
    "            if c_f in self.raw_data:\n",
    "                self.raw_data.sort(order=c_f)\n",
    "            is_date = c_f.find('date') >= 0\n",
    "            if is_date:\n",
    "                self.raw_data.sort(order=c_f)\n",
    "            else:\n",
    "                self.normalized_data.sort(order=c_f)\n",
    "            for c_t in self.targets:\n",
    "                try:\n",
    "                    f = plt.figure()\n",
    "                    if is_discrete:\n",
    "                        d = mlab.rec_groupby(self.normalized_data, [c_f], [(c_t, numpy.average, 'avg')])\n",
    "                        plt.bar(d[c_f], d['avg'])\n",
    "                    else:\n",
    "                        y = None\n",
    "                        if c_t in self.raw_data and self.raw_data[c_t].dtype == '>f4':\n",
    "                            y = self.raw_data[c_t]\n",
    "                        else:\n",
    "                            y = self.normalized_data[c_t]        \n",
    "                            convolved_y = numpy.convolve(numpy.ones(smoothing_window, 'd')/smoothing_window, y, mode='valid')\n",
    "                            x = self.raw_data[c_f] if is_date else self.normalized_data[c_f]\n",
    "                            plt.plot(x[0:convolved_y.shape[0]], convolved_y)\n",
    "                            if is_date: f.autofmt_xdate()\n",
    "                    plt.ylabel(c_t)\n",
    "                    plt.xlabel(c_f)\n",
    "                    plt.savefig(\"%s/%s_x_%s\" % ('plots', c_f, c_t))\n",
    "                except:\n",
    "                    print \"Error creating plot (%s, %s)\" % (c_f, c_t)\n",
    "\n",
    "\n",
    "class LcData:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.csv_columns = [\"loan_id\",\"amount_requested\",\"amount_funded_by_investors\",\"interest_rate\",\"loan_length\",\"application_date\",\"application_expiration_date\",\"issued_date\",\"credit_grade\",\"loan_title\",\"loan_purpose\",\"loan_description\",\"monthly_payment\",\"status\",\"total_amount_funded\",\"debt_to_income_ratio\",\"remaining_principal_funded_by_investors\",\"payments_to_date_funded_by_investors_\",\"remaining_principal_\",\"payments_to_date\",\"screen_name\",\"city\",\"state\",\"home_ownership\",\"monthly_income\",\"fico_range\",\"earliest_credit_line_date\",\"open_credit_lines\",\"total_credit_lines\",\"revolving_credit_balance\",\"revolving_line_utilization\",\"inquiries_in_the_last_6_months\",\"accounts_now_delinquent\",\"delinquent_amount\",\"delinquencies__last_2_yrs_\",\"months_since_last_delinquency\",\"public_records_on_file\",\"months_since_last_record\",\"education\",\"employment_length\",\"code\"]\n",
    "\n",
    "\n",
    "    def load_csv(self, fname):\n",
    "        def clean_csv():\n",
    "            print \"Reading csv from file %s\" % (fname)\n",
    "            reader = csv.reader(open(fname, 'rb'))\n",
    "            cleaned_fname = \"/tmp/lc-%s.csv\" % (random.random())\n",
    "            print \"Cleaning csv file using python csv library, writing new file to %s\" % (cleaned_fname)\n",
    "            writer = csv.writer(open(cleaned_fname, 'wb'))\n",
    "            for i, row in enumerate(reader):\n",
    "                # skip first 2 rows\n",
    "                if i < 2: continue\n",
    "                if len(self.csv_columns) == len(row):\n",
    "                    writer.writerow(row)\n",
    "                else:\n",
    "                    print \"\\tError row %d, line contents:\\\"%s\\\"\" % (i, \", \".join(row))\n",
    "            return cleaned_fname\n",
    "\n",
    "        cleaned_fname = clean_csv()\n",
    "        converterd = {'interest_rate': fieldparsers.strip_non_numeric_and_parse,\n",
    "                      'loan_length': fieldparsers.strip_non_numeric_and_parse,\n",
    "                      'employment_length': fieldparsers.parse_employment_years,\n",
    "                      'debt_to_income_ratio': fieldparsers.strip_non_numeric_and_parse,\n",
    "                      'revolving_line_utilization': fieldparsers.strip_non_numeric_and_parse,\n",
    "                      'status': fieldparsers.parse_status\n",
    "                      }\n",
    "        print \"Loading csv via mlab\"\n",
    "        self.data = mlab.csv2rec(cleaned_fname, skiprows=2, converterd=converterd, names=self.csv_columns)\n",
    "        subprocess.call([\"rm\", \"-rf\", cleaned_fname])\n",
    "        print \"Done.\"\n",
    "\n",
    "    def exclude_values(self, col, values):\n",
    "        indexes = numpy.where(numpy.all([self.data[col] != v for v in values], axis=0))\n",
    "        return self.data[indexes]\n",
    "\n",
    "def run(filename):\n",
    "    lc_data = LcData()\n",
    "    lc_data.load_csv(filename)\n",
    "    status_types_to_exclude = ['Issued', 'In Review', 'Current']\n",
    "    csv_data = lc_data.exclude_values('status', status_types_to_exclude)\n",
    "    print \"Removed status types [%s], num rows resulting: %d\" % (\", \".join(status_types_to_exclude), csv_data.shape[0])\n",
    "    csv_data.sort(order='application_date')\n",
    "    lc_data_features = LcDataExtractedFeatures()\n",
    "    lc_data_features.create(csv_data)\n",
    "    targets = ['status', 'expected_interest_rate', 'interest_rate']\n",
    "    features = ['one', 'amount_requested', 'interest_rate', 'application_date', 'credit_grade', 'debt_to_income_ratio', 'monthly_income', 'fico_range', 'open_credit_lines', 'total_credit_lines', 'earliest_credit_line_date', 'home_ownership', 'description_length']\n",
    "    plotter = LcPlotter(csv_data, lc_data_features.data, features, targets)\n",
    "    plotter.plot_correlations()\n",
    "    lc_learner = LcLearner(lc_data_features.data, csv_data)\n",
    "    lc_learner.evaluate_all(features, 'status')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run(sys.argv[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
